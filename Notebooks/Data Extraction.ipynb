{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6384737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number = 1\n",
    "initial_url = 'https://jobinja.ir/jobs?&b=&filters%5Bjob_categories%5D%5B0%5D=&filters%5Bkeywords%5D%5B0%5D=&filters%5Blocations%5D%5B0%5D='\n",
    "\n",
    "# Create an empty list to store job data dictionaries\n",
    "job_data_list = []\n",
    "\n",
    "for i in range(1,10):\n",
    "    url = initial_url + f'&page={page_number}'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        break  # Stop crawling if the page is not accessible or doesn't exist\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    job_links = soup.find_all('a', class_='c-jobListView__titleLink')\n",
    "\n",
    "    if not job_links:\n",
    "        break  # Stop crawling if there are no job links on the page\n",
    "\n",
    "    for job_link in job_links:\n",
    "        job_url = job_link['href']\n",
    "        job_response = requests.get(job_url)\n",
    "\n",
    "        if job_response.status_code == 200:\n",
    "            job_soup = BeautifulSoup(job_response.content, 'html.parser')\n",
    "            company_name_element = job_soup.find('h2', class_='c-companyHeader__name')\n",
    "    \n",
    "            # Get the company name (both Persian and English)\n",
    "            company_name = company_name_element.text.strip().split('|')[0].strip()\n",
    "    \n",
    "            # Find the company meta information\n",
    "            company_meta_elements = job_soup.find_all('span', class_='c-companyHeader__metaItem')\n",
    "            \n",
    "            # i wish whoever came up with this name tagging idea for the website a painful death i had\n",
    "            # to start over two times after crawling through the entire website, scraping 26k data because\n",
    "            # around 2.5k fields (around 10% of data) in company category/size had their values switched up...\n",
    "            if len(company_meta_elements) > 3:\n",
    "                print(len(company_meta_elements))\n",
    "                \n",
    "                company_category = company_meta_elements[1].find('a', class_='c-companyHeader__metaLink').text.strip()\n",
    "                company_size = company_meta_elements[2].text.strip()\n",
    "                company_website = company_meta_elements[3].find('a', class_='c-companyHeader__metaLink').text.strip()\n",
    "            else:\n",
    "                # Get the company category (only the Persian phrase)\n",
    "                company_category_element = company_meta_elements[0].find('a', class_='c-companyHeader__metaLink')\n",
    "                company_category = company_category_element.text.strip() if company_category_element else ''\n",
    "        \n",
    "                # Get the company size (only the Persian phrase)\n",
    "                company_size = company_meta_elements[1].text.strip() if len(company_meta_elements) > 1 else ''\n",
    "        \n",
    "                # Get the company website (if available)\n",
    "                company_website_element = company_meta_elements[-1].find('a', class_='c-companyHeader__metaLink', target='_blank')\n",
    "                company_website = company_website_element['href'].replace('https://', '').replace('http://', '').replace('/', '') if company_website_element else ''\n",
    "                \n",
    "            \n",
    "    \n",
    "            # Get the job position\n",
    "            job_position_element = job_soup.find('div', class_='c-jobView__title').find('h1')\n",
    "            job_position = job_position_element.text.strip() if job_position_element else ''\n",
    "            \n",
    "            # Pulling all 5 elements from the job info box\n",
    "            info_box_element = job_soup.find('ul', class_='c-jobView__firstInfoBox c-infoBox').find_all('li', class_='c-infoBox__item')\n",
    "            \n",
    "            # Job category\n",
    "            job_category = info_box_element[0].find('span', class_='black').text.strip()\n",
    "            \n",
    "            # Job location\n",
    "            job_location = info_box_element[1].find('span', class_='black').text.strip().split('،')[0].strip()\n",
    "            \n",
    "            # Job employment type\n",
    "            job_employment_type = info_box_element[2].find('span', class_='black').text.strip()\n",
    "            \n",
    "            # Job least experience needed\n",
    "            job_experience = info_box_element[3].find('span', class_='black').text.strip()\n",
    "            \n",
    "            # Job salary\n",
    "            job_salary = info_box_element[4].find('span', class_='black').text.strip()\n",
    "            \n",
    "            \n",
    "            # Find the skills box\n",
    "            skills_box_element = job_soup.find('ul', class_='c-infoBox u-mB0')\n",
    "            skills_li_element = skills_box_element.find('h4', text='مهارت‌های مورد نیاز').parent\n",
    "            # Get all the skill tags with class \"black\" within the skills box\n",
    "            skill_tags = skills_li_element.find_all('span', class_='black')\n",
    "            # Extract the skills and join them with a comma\n",
    "            skills = ', '.join(skill_tag.text.strip() for skill_tag in skill_tags)\n",
    "    \n",
    "            # Find the gender box\n",
    "            try:\n",
    "                gender_li_element = skills_box_element.find('h4', text='جنسیت').parent\n",
    "                gender = gender_li_element.find('span', class_='black').text.strip()\n",
    "            except AttributeError:\n",
    "                gender = ''\n",
    "    \n",
    "            # Find the military service box (is None when gender is set to 'female')\n",
    "            try:\n",
    "                military_service_li_element = skills_box_element.find('h4', text='وضعیت نظام وظیفه').parent\n",
    "                military_service = military_service_li_element.find('span', class_='black').text.strip()\n",
    "            except AttributeError:\n",
    "                military_service = ''\n",
    "    \n",
    "            # Find the education box\n",
    "            try:\n",
    "                education_li_element = skills_box_element.find('h4', text='حداقل مدرک تحصیلی').parent\n",
    "                education = education_li_element.find('span', class_='black').text.strip()\n",
    "            except AttributeError:\n",
    "                education = ''\n",
    "    \n",
    "            # Find the job description\n",
    "            job_description_element = job_soup.find('div', class_='o-box__text s-jobDesc c-pr40p')\n",
    "            job_description = job_description_element.get_text(strip=True) if job_description_element else ''\n",
    "            \n",
    "            \n",
    "            # Append the job data to the list\n",
    "            job_data_list.append({\n",
    "                'Job Position': job_position,\n",
    "                'Job Category': job_category,\n",
    "                'Job Location': job_location,\n",
    "                'Employment Type': job_employment_type,\n",
    "                'Experience': job_experience,\n",
    "                'Salary': job_salary,\n",
    "                'Company Name': company_name,\n",
    "                'Company Category': company_category,\n",
    "                'Company Size': company_size,\n",
    "                'Company Website': company_website,\n",
    "                'Skills': skills,\n",
    "                'Gender': gender,\n",
    "                'Military Service': military_service,\n",
    "                'Education': education,\n",
    "                'Job Description': job_description,\n",
    "                'Job URL': job_url\n",
    "            })\n",
    "    \n",
    "            # Checks\n",
    "            print(company_name)\n",
    "            print(company_category)\n",
    "            print(company_size)\n",
    "            print(company_website)\n",
    "            print(job_position)\n",
    "            print(job_category)\n",
    "            print(job_location)\n",
    "            print(job_employment_type)\n",
    "            print(job_experience)\n",
    "            print(job_salary)\n",
    "            print(skills)\n",
    "            print(gender)\n",
    "            print(military_service)\n",
    "            print(education)\n",
    "            print(job_description)\n",
    "            print(job_url)\n",
    "            print('-' * 50)\n",
    "\n",
    "# Create a DataFrame from the collected job data list\n",
    "df = pd.DataFrame(job_data_list)\n",
    "\n",
    "# Print the DataFrame with the collected job specifications\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_data(job_soup):\n",
    "    # Get the company name (both Persian and English)\n",
    "    company_name_element = job_soup.find('h2', class_='c-companyHeader__name')\n",
    "    company_name = company_name_element.text.strip().split('|')[0].strip()\n",
    "\n",
    "    # Find the company meta information\n",
    "    company_meta_elements = job_soup.find_all('span', class_='c-companyHeader__metaItem')\n",
    "\n",
    "    # Get the company category (only the Persian phrase)\n",
    "    company_category_element = company_meta_elements[0].find('a', class_='c-companyHeader__metaLink')\n",
    "    company_category = company_category_element.text.strip() if company_category_element else ''\n",
    "\n",
    "    # Get the company size (only the Persian phrase)\n",
    "    company_size = company_meta_elements[1].text.strip() if len(company_meta_elements) > 1 else ''\n",
    "\n",
    "    # Get the company website (if available)\n",
    "    company_website_element = company_meta_elements[-1].find('a', class_='c-companyHeader__metaLink', target='_blank')\n",
    "    company_website = company_website_element['href'].replace('https://', '').replace('http://', '').replace('/', '') if company_website_element else ''\n",
    "\n",
    "    # Get the job position\n",
    "    job_position_element = job_soup.find('div', class_='c-jobView__title').find('h1')\n",
    "    job_position = job_position_element.text.strip() if job_position_element else ''\n",
    "\n",
    "    # Find the skills box\n",
    "    skills_box_element = job_soup.find('ul', class_='c-infoBox u-mB0')\n",
    "    skills_li_element = skills_box_element.find('h4', text='مهارت‌های مورد نیاز').parent\n",
    "    # Get all the skill tags with class \"black\" within the skills box\n",
    "    skill_tags = skills_li_element.find_all('span', class_='black')\n",
    "    # Extract the skills and join them with a comma\n",
    "    skills = ', '.join(skill_tag.text.strip() for skill_tag in skill_tags)\n",
    "\n",
    "    # Find the gender box\n",
    "    try:\n",
    "        gender_li_element = skills_box_element.find('h4', text='جنسیت').parent\n",
    "        gender = gender_li_element.find('span', class_='black').text.strip()\n",
    "    except AttributeError:\n",
    "        gender = ''\n",
    "\n",
    "    # Find the military service box (is None when gender is set to 'female')\n",
    "    try:\n",
    "        military_service_li_element = skills_box_element.find('h4', text='وضعیت نظام وظیفه').parent\n",
    "        military_service = military_service_li_element.find('span', class_='black').text.strip()\n",
    "    except AttributeError:\n",
    "        military_service = ''\n",
    "\n",
    "    # Find the education box\n",
    "    try:\n",
    "        education_li_element = skills_box_element.find('h4', text='حداقل مدرک تحصیلی').parent\n",
    "        education = education_li_element.find('span', class_='black').text.strip()\n",
    "    except AttributeError:\n",
    "        education = ''\n",
    "\n",
    "    # Find the job description\n",
    "    job_description_element = job_soup.find('div', class_='o-box__text s-jobDesc c-pr40p')\n",
    "    job_description = job_description_element.get_text(strip=True) if job_description_element else ''\n",
    "    \n",
    "    return {\n",
    "        'Job Category': job_category,\n",
    "        'Job Position': job_position,\n",
    "        'Company Name': company_name,\n",
    "        'Company Category': company_category,\n",
    "        'Company Size': company_size,\n",
    "        'Company Website': company_website,\n",
    "        'Skills': skills,\n",
    "        'Gender': gender,\n",
    "        'Military Service': military_service,\n",
    "        'Education': education,\n",
    "        'Job Description': job_description\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2396ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_job_data():\n",
    "    initial_url = 'https://jobinja.ir/jobs?&b=&filters%5Bjob_categories%5D%5B0%5D=&filters%5Bkeywords%5D%5B0%5D=&filters%5Blocations%5D%5B0%5D='\n",
    "\n",
    "    # Create an empty list to store job data dictionaries\n",
    "    job_data_list = []\n",
    "    page_number = 1\n",
    "\n",
    "    while page_number <= 5:\n",
    "        url = initial_url + f'&page={page_number}'\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            break  # Stop crawling if the page is not accessible or doesn't exist\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        job_links = soup.find_all('a', class_='c-jobListView__titleLink')\n",
    "\n",
    "        if not job_links:\n",
    "            break  # Stop crawling if there are no job links on the page\n",
    "\n",
    "        for entry, job_link in enumerate(job_links, 1):\n",
    "            job_url = job_link['href']\n",
    "            job_response = requests.get(job_url)\n",
    "\n",
    "            if job_response.status_code == 200:\n",
    "                job_soup = BeautifulSoup(job_response.content, 'html.parser')\n",
    "                job_data = extract_job_data(job_soup)\n",
    "                job_data['Job URL'] = job_url\n",
    "\n",
    "                # Append the job data to the list\n",
    "                job_data_list.append(job_data)\n",
    "\n",
    "                # Print processing information for each job entry\n",
    "                print(f\"Processing Page: {page_number} - Entry: {entry}\")\n",
    "\n",
    "        page_number += 1\n",
    "        print(f'20 Entries from {page_number} appended to the DataFrame')\n",
    "\n",
    "\n",
    "    return job_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_number = 1\n",
    "job_data_list = crawl_job_data()\n",
    "\n",
    "# Create a DataFrame from the collected job data list\n",
    "df = pd.DataFrame(job_data_list)\n",
    "\n",
    "# Print the DataFrame with the collected job specifications\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293aeef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79f365",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Employment Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83966368",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Jobinja.csv', index=False, encoding='utf-8-sig')# Print the DataFrame with the collected job specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac05d184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
